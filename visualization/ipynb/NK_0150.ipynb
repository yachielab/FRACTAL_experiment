{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import random\n",
    "import os\n",
    "import sys \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO, Phylo\n",
    "import gzip\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "random.seed(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.chdir(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0150\")\n",
    "\n",
    "for dirname in [\"table\", \"figures\"]:\n",
    "    try:\n",
    "        os.mkdir(dirname)\n",
    "    except:\n",
    "        None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_clade_seq_entropy = pd.read_table(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0150/from_yusuke/entropy.clade_to_tiplist.all.long.tsv\")\n",
    "df_clade_seq_entropy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_seq_Nmutations = pd.read_table(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0150/from_yusuke/result/name_seqdist.bcat.txt\", names = ['Tip', 'Nmutations', 'Nsubstitutions', 'Ndeletions'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_merge = pd.merge(df_clade_seq_entropy, df_seq_Nmutations, on = 'Tip')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "records = SeqIO.parse(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0150/fasta/root.bcat.fa\", 'fasta')\n",
    "\n",
    "for record in records:\n",
    "    root_seq = str(record.seq)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "records = SeqIO.parse(gzip.open(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0150/from_ikaken/bcat_parent_delsub.SEQUENCE.fa.gz\",'rt'), 'fasta')\n",
    "name2parentseq = {}\n",
    "for record in records:\n",
    "    name2parentseq[record.name] = str(record.seq)\n",
    "\n",
    "# most abundantなリードを取得した\n",
    "well2parentseq = {}\n",
    "for name in name2parentseq.keys():\n",
    "    if (name.split(\"_\")[1] == \"1\"):\n",
    "        well2parentseq[name.split(\"_\")[0]] = str(name2parentseq[name])\n",
    "\n",
    "# B10とE3はdeletionがポジションの過半数を占めた\n",
    "# B10については探してもどのparentもdeletionがポジションの過半数をしめていた\n",
    "# E3についてはE3_5がdeletionの少ない配列だったのでそちらに交換した\n",
    "\n",
    "#well2parentseq['E3'] =name2parentseq['E3_5']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "name_Nparentmutation_Ninheritedmutation_Nmismatchtoparent = []\n",
    "\n",
    "records = SeqIO.parse(gzip.open(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0150/from_idenken/fractalin.bcat.fa.gz\",'rt'), 'fasta')\n",
    "name2seq = {}\n",
    "for record in records:\n",
    "    name2seq[record.name] = str(record.seq)\n",
    "    if (record.name != \"root\"):\n",
    "        seq       = str(record.seq)\n",
    "        well      = (record.name).split(\"_\")[3]\n",
    "        parentseq = well2parentseq[well]\n",
    "\n",
    "        count_parentmutation    = 0\n",
    "        count_inheritedmutation = 0\n",
    "        count_mismatchtoparent  = 0\n",
    "        count_revertant         = 0\n",
    "        for i in range(len(root_seq)):\n",
    "            if root_seq[i] != parentseq[i]:\n",
    "                count_parentmutation += 1\n",
    "                if seq[i]  == parentseq[i]:\n",
    "                    count_inheritedmutation += 1\n",
    "                elif seq[i] == root_seq[i]:\n",
    "                    count_revertant += 1\n",
    "            if seq[i]  != parentseq[i]:\n",
    "                count_mismatchtoparent += 1\n",
    "        name_Nparentmutation_Ninheritedmutation_Nmismatchtoparent.append([record.name, count_parentmutation, count_inheritedmutation,count_mismatchtoparent, count_revertant])\n",
    "\n",
    "df_parentdist = pd.DataFrame(name_Nparentmutation_Ninheritedmutation_Nmismatchtoparent, columns = [\"Tip\", \"Nparentmut\", \"Ninheritmut\", \"Nmismatch2parent\", \"Nrevertant\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_parentdist"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_merge = pd.merge(df_merge, df_parentdist, on ='Tip')\n",
    "df_merge[\"Reverted_position_ratio\"] = df_merge['Nrevertant']/df_merge['Nparentmut']\n",
    "df_merge[\"Normalized_Reverted_position_ratio\"] = (df_merge['Nrevertant']/df_merge['Nparentmut']) / (df_merge['Nmismatch2parent']/198)\n",
    "df_merge"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for target in ['Nmutations', 'Nsubstitutions', 'Ndeletions']:\n",
    "    fig = plt.figure(figsize=(3,2))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "\n",
    "    ax.hist(df_merge[target], range(0,198))\n",
    "\n",
    "    ax.set_xlabel(target)\n",
    "    ax.set_ylabel(\"# seq\")\n",
    "    ax.set_xlim(0,198)\n",
    "    #ax.set_ylim(1,300000)\n",
    "    plt.savefig(\"figures/histogram_\"+target+\".pdf\", bbox_inches='tight')\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylim(1,2000000)\n",
    "    plt.savefig(\"figures/histogram_\"+target+\"_log.pdf\", bbox_inches='tight')\n",
    "    #plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_clade = df_merge.groupby('Clade').mean()\n",
    "df_clade['Ndata'] = df_merge.groupby('Clade').count()['Nmutations']\n",
    "\n",
    "df_clade.to_csv(\"table/clade_entropy_aveNmutations_Ndata.txt\", sep = \"\\t\")\n",
    "\n",
    "# 以下 X配列以上含むクレードのみ解析対象とする\n",
    "X = 1000\n",
    "df_clade = df_clade[df_clade['Ndata'] > X]\n",
    "#df_clade"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for target in ['Nmutations', 'Nsubstitutions', 'Ndeletions']:\n",
    "    fig = plt.figure(figsize=(2,2))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "\n",
    "    plt.scatter(df_clade['Entropy'], df_clade[target], alpha = 0.5, s = 1)\n",
    "\n",
    "    ax.set_ylim(0,50)\n",
    "\n",
    "    ax.set_xlabel(\"Entropy\")\n",
    "    ax.set_ylabel(target)\n",
    "    ax.set_title(\"Clade size > \"+str(X), fontsize = 10)\n",
    "\n",
    "    plt.savefig(\"figures/Entropy_\"+target+\"_\"+str(X)+\".pdf\", bbox_inches='tight')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "entropy_threshold = 1\n",
    "\n",
    "for target in ['Nmutations', 'Nsubstitutions', 'Ndeletions']:\n",
    "\n",
    "    fig = plt.figure(figsize=(2,2))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    df_clade[\"Mixed\"] = [True if entropy > entropy_threshold else False for entropy in df_clade['Entropy']]\n",
    "\n",
    "    sns.violinplot(data = df_clade, y = target, x = 'Mixed')\n",
    "    ax.set_xlabel(\"Entropy > \"+str(entropy_threshold))\n",
    "    ax.set_ylabel(\"Mean \"+target)\n",
    "    ax.set_title(\"Clade size > \"+str(X), fontsize = 10)\n",
    "    ax.set_ylim(0,50)\n",
    "    plt.savefig(\"figures/\"+target+\"_distribution_\"+str(X)+\".pdf\", bbox_inches='tight')\n",
    "\n",
    "for target in ['Reverted_position_ratio']:\n",
    "\n",
    "    fig = plt.figure(figsize=(2,2))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    df_clade[\"Mixed\"] = [True if entropy > entropy_threshold else False for entropy in df_clade['Entropy']]\n",
    "\n",
    "    sns.violinplot(data = df_clade, y = target, x = 'Mixed')\n",
    "    ax.set_xlabel(\"Entropy > \"+str(entropy_threshold))\n",
    "    ax.set_ylabel(\"Mean \"+target)\n",
    "    ax.set_title(\"Clade size > \"+str(X), fontsize = 10)\n",
    "    ax.set_ylim(0,1)\n",
    "    plt.savefig(\"figures/\"+target+\"_distribution_\"+str(X)+\".pdf\", bbox_inches='tight')\n",
    "\n",
    "for target in ['Normalized_Reverted_position_ratio']:\n",
    "\n",
    "    fig = plt.figure(figsize=(2,2))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    df_clade[\"Mixed\"] = [True if entropy > entropy_threshold else False for entropy in df_clade['Entropy']]\n",
    "\n",
    "    sns.violinplot(data = df_clade, y = target, x = 'Mixed')\n",
    "    ax.set_xlabel(\"Entropy > \"+str(entropy_threshold))\n",
    "    ax.set_ylabel(\"Mean \"+target)\n",
    "    ax.set_title(\"Clade size > \"+str(X), fontsize = 10)\n",
    "    #ax.set_ylim(0,1)\n",
    "    plt.savefig(\"figures/\"+target+\"_distribution_\"+str(X)+\".pdf\", bbox_inches='tight')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_merge['Well'] = [tip.split(\"_\")[3] for tip in df_merge['Tip']]\n",
    "\n",
    "fig = plt.figure(figsize=(2,1))\n",
    "for i, idx_alphabet in enumerate(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']):\n",
    "    for j in range(12):\n",
    "        well = idx_alphabet + str(j+1)\n",
    "\n",
    "        df_merge_ext = df_merge[df_merge['Well'] == well].sort_values(\"Entropy\")\n",
    "        ax = fig.add_axes([0.1+i*1.2,0.1+j*1.4,0.8,0.8])\n",
    "\n",
    "        ax.hist(df_merge_ext['Entropy'], range = (0,6.5), bins = 13)\n",
    "\n",
    "        ax.set_title(plate, fontsize = 10)\n",
    "        if (j == 0): ax.set_xlabel(\"Entropy\")\n",
    "        if (i == 0): ax.set_ylabel(\"# seq\")\n",
    "        ax.set_xlim(0,6.5)\n",
    "        #ax.set_ylim(1,300000)\n",
    "plt.savefig(\"figures/entropy_histogram_wells.pdf\", bbox_inches='tight')\n",
    "plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(2,1))\n",
    "for i, idx_alphabet in enumerate(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']):\n",
    "    for j in range(12):\n",
    "        well = idx_alphabet + str(j+1)\n",
    "\n",
    "        df_merge_ext = df_merge[df_merge['Well'] == well]\n",
    "        ax = fig.add_axes([0.1+i*1.2,0.1+j*1.4,0.8,0.8])\n",
    "\n",
    "        ax.hist(df_merge_ext['Ninheritmut'], range = (0, 30), bins = 31)\n",
    "\n",
    "        ax.set_title(well, fontsize = 10) \n",
    "        if (j == 0): ax.set_xlabel(\"# inherited from parent\")\n",
    "        if (i == 0): ax.set_ylabel(\"# seq\")\n",
    "        ax.set_xlim(0,31)\n",
    "        #ax.set_ylim(1,300000)\n",
    "plt.savefig(\"figures/Ninherited_histogram_wells.pdf\", bbox_inches='tight')\n",
    "plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(2,1))\n",
    "for i, idx_alphabet in enumerate(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']):\n",
    "    for j in range(12):\n",
    "        well = idx_alphabet + str(j+1)\n",
    "\n",
    "        df_merge_ext = df_merge[df_merge['Well'] == well]\n",
    "        ax = fig.add_axes([0.1+i*1.2,0.1+j*1.4,0.8,0.8])\n",
    "\n",
    "        ax.hist(df_merge_ext['Ninheritmut']/df_merge_ext['Nparen tmut'], range = (0, 1), bins = 20)\n",
    "\n",
    "        df_merge_ext_messy = df_merge_ext[df_merge_ext['Entropy'] > 1]\n",
    "\n",
    "        ax.hist(df_merge_ext_messy['Ninheritmut']/df_merge_ext_messy['Nparentmut'], range = (0, 1), bins = 20)\n",
    "\n",
    "        \n",
    "\n",
    "        ax.set_title(well, fontsize = 10) \n",
    "        if (j == 0): ax.set_xlabel(\"Inherited ratio\")\n",
    "        if (i == 0): ax.set_ylabel(\"# seq\")\n",
    "        ax.set_xlim(0,1)\n",
    "        #ax.set_ylim(1,300000)\n",
    "plt.savefig(\"figures/Ninheritedratio_histogram_wells.pdf\", bbox_inches='tight')\n",
    "plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(2,1))\n",
    "for i, idx_alphabet in enumerate(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']):\n",
    "    for j in range(12):\n",
    "        well = idx_alphabet + str(j+1)\n",
    "\n",
    "        df_merge_ext = df_merge[df_merge['Well'] == well]\n",
    "        ax = fig.add_axes([0.1+i*1.2,0.1+j*1.4,0.8,0.8])\n",
    "\n",
    "        ax.hist(df_merge_ext['Nrevertant']/df_merge_ext['Nparentmut'], range = (0, 1), bins = 20)\n",
    "\n",
    "        df_merge_ext_messy = df_merge_ext[df_merge_ext['Entropy'] > 1]\n",
    "\n",
    "        ax.hist(df_merge_ext_messy['Nrevertant']/df_merge_ext_messy['Nparentmut'], range = (0, 1), bins = 20)\n",
    "\n",
    "        ax.set_title(well, fontsize = 10) \n",
    "        if (j == 0): ax.set_xlabel(\"Reverted position ratio\")\n",
    "        if (i == 0): ax.set_ylabel(\"# seq \")\n",
    "        ax.set_xlim(0,1)\n",
    "        #ax.set_ylim(1,300000)\n",
    "plt.savefig(\"figures/Nrevertantratio_histogram_wells.pdf\", bbox_inches='tight')\n",
    "plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(2,1))\n",
    "\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax.hist(df_merge['Nrevertant']/df_merge['Nparentmut'], range = (0, 1), bins = 20)\n",
    "df_merge_messy = df_merge[df_merge['Entropy'] > 1]\n",
    "ax.hist(df_merge_messy['Nrevertant']/df_merge_messy['Nparentmut'], range = (0, 1), bins = 20)\n",
    "ax.set_title(\"All\", fontsize = 10)\n",
    "ax.set_xlabel(\"Reverted position ratio\")\n",
    "ax.set_ylabel(\"# seq \")\n",
    "ax.set_xlim(0,1)\n",
    "#ax.set_ylim(1,300000)\n",
    "plt.savefig(\"figures/Nrevertantratio_histogram_total.pdf\", bbox_inches='tight')\n",
    "plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plate = 'A1'\n",
    "df_merge_ext = df_merge[df_merge['Well'] == plate].sort_values(\"Entropy\")\n",
    "df_merge_ext.to_csv(\"table/\"+plate+\"_seq_table.txt\", index = False, sep = '\\t')\n",
    "\n",
    "seq = []\n",
    "\n",
    "records = SeqIO.parse(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0150/fasta/root.bcat.fa\", 'fasta')\n",
    "\n",
    "for record in records:\n",
    "    root_seq = str(record.seq)\n",
    "\n",
    "ATGC2int = {'A':1, 'T':2, 'G':3, 'C':4, '-':5}\n",
    "\n",
    "seq_table = []\n",
    "records = SeqIO.parse(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0150/fasta/\"+plate+\"_sample.fa\", 'fasta')\n",
    "\n",
    "for record in records:\n",
    "    seq = str(record.seq)\n",
    "\n",
    "    seq_row = []\n",
    "\n",
    "    for i in range(len(seq)):\n",
    "        if(seq[i] == root_seq[i]):\n",
    "            seq_row.append(0)\n",
    "        else:\n",
    "            seq_row.append(ATGC2int[seq[i]])\n",
    "    seq_table.append(seq_row)\n",
    "\n",
    "df_seq_table = pd.DataFrame(seq_table)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax2 = fig.add_axes([1.0,0.1,0.05,0.2])\n",
    "ax.set_title(plate)\n",
    "#ax.imshow(df_seq_table, cmap = 'tab10', aspect = 0.5)\n",
    "sns.heatmap(df_seq_table, cmap = 'terrain_r', ax = ax, cbar_ax = ax2)\n",
    "plt.savefig(\"figures/sequence_heatmap_\"+plate+\".pdf\", bbox_inches='tight')\n",
    "plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clade_name = 'Clade3977'\n",
    "\n",
    "records = SeqIO.parse(gzip.open(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0150/from_idenken/fractalin.bcat.fa.gz\",'rt'), 'fasta')\n",
    "name2seq = {}\n",
    "for record in records:\n",
    "    name2seq[record.name] = str(record.seq)\n",
    "\n",
    "seq_to_visualize_list = []\n",
    "well_list = []\n",
    "for i, idx_alphabet in enumerate(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']):\n",
    "    for j in range(12):\n",
    "        well = idx_alphabet + str(j+1)\n",
    "        df_merge_ext = df_merge[df_merge['Clade']==clade_name][df_merge[\"Plate\"]==well]\n",
    "        if(len(list(df_merge_ext['Tip']))>10):\n",
    "            seqnames = random.sample(list(df_merge_ext['Tip']), 10)\n",
    "            seq_to_visualize_list.extend([name2seq[name] for name in seqnames])\n",
    "            well_list.append(well)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "ATGC2int = {'A':1, 'T':2, 'G':3, 'C':4, '-':5}\n",
    "\n",
    "seq_table = []\n",
    "\n",
    "for seq in seq_to_visualize_list:\n",
    "\n",
    "    seq_row = []\n",
    "\n",
    "    for i in range(len(seq)):\n",
    "        if(seq[i] == root_seq[i]):\n",
    "            seq_row.append(0)\n",
    "        else:\n",
    "            seq_row.append(ATGC2int[seq[i]])\n",
    "    seq_table.append(seq_row)\n",
    "\n",
    "df_seq_table = pd.DataFrame(seq_table)\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax2 = fig.add_axes([1.0,0.1,0.05,0.2])\n",
    "#ax.imshow(df_seq_table, cmap = 'terrain_r', aspect = 0.5)\n",
    "sns.heatmap(df_seq_table, cmap = 'terrain_r', ax = ax, cbar_ax = ax2)\n",
    "\n",
    "ax.set_xlabel(\"Sequence position\")\n",
    "\n",
    "ax.set_ylabel(\"Sequences\")\n",
    "\n",
    "ax.set_title(clade_name)\n",
    "\n",
    "ax.set_yticks([10*i for i in range(int(len(seq_to_visualize_list)/10))])\n",
    "ax.set_yticklabels(well_list, fontsize = 5)\n",
    "\n",
    "plt.savefig(\"figures/sequence_heatmap_\"+clade_name+\".pdf\", bbox_inches='tight')\n",
    "\n",
    "plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#クレード内配列間距離の計算\n",
    "cladename_meanhd_list = []\n",
    "\n",
    "for k, clade_name in enumerate(list(set(df_clade.index))):\n",
    "\n",
    "    #print(k, clade_name)\n",
    "    seq_name_list = list(df_merge[df_merge['Clade']==clade_name].Tip)\n",
    "    count_list    = []\n",
    "    for _ in range(1000):\n",
    "        sample_seq_name_list = random.sample(seq_name_list,2)\n",
    "        str1 = name2seq[sample_seq_name_list[0]]\n",
    "        str2 = name2seq[sample_seq_name_list[1]]\n",
    "        count = 0\n",
    "        for i in range(len(str1)):\n",
    "            if (str1[i] != str2[i]):\n",
    "                count += 1\n",
    "        count_list.append(count)\n",
    "    hd = sum(count_list) / len(count_list)\n",
    "\n",
    "    cladename_meanhd_list.append([clade_name, hd])\n",
    "\n",
    "# all clades\n",
    "seq_name_list = list(df_merge.Tip)\n",
    "for _ in range(1000):\n",
    "    sample_seq_name_list = random.sample(seq_name_list,2)\n",
    "    str1 = name2seq[sample_seq_name_list[0]]\n",
    "    str2 = name2seq[sample_seq_name_list[1]]\n",
    "    count = 0\n",
    "    for i in range(len(str1)):\n",
    "        if (str1[i] != str2[i]):\n",
    "            count += 1\n",
    "    count_list.append(count)\n",
    "hd = sum(count_list) / len(count_list)\n",
    "mean_hd_all_clades = hd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_cladename_meanhd = pd.DataFrame(cladename_meanhd_list, columns= ['Clade_', 'meanhd'], index = [cladename_meanhd[0] for cladename_meanhd in cladename_meanhd_list])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_clade['Clade_']  = df_clade.index\n",
    "df_clade_hd = pd.merge(df_cladename_meanhd, df_clade, on = 'Clade_')\n",
    "df_clade_hd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for target in ['meanhd']:\n",
    "    fig = plt.figure(figsize=(2,2))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "\n",
    "    plt.scatter(df_clade_hd['Entropy'], df_clade_hd[target], alpha = 0.5, s = 1)\n",
    "\n",
    "    ax.set_ylim(0,50)\n",
    "\n",
    "    ax.set_xlabel(\"Entropy\")\n",
    "    ax.set_ylabel(target)\n",
    "    ax.set_title(\"Clade size > \"+str(X), fontsize = 10)\n",
    "\n",
    "    plt.savefig(\"figures/Entropy_\"+target+\"_\"+str(X)+\".pdf\", bbox_inches='tight')\n",
    "\n",
    "for target in ['meanhd']:\n",
    "\n",
    "    fig = plt.figure(figsize=(2,2))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    df_clade[\"Mixed\"] = [True if entropy > entropy_threshold else False for entropy in df_clade['Entropy']]\n",
    "\n",
    "    sns.violinplot(data = df_clade_hd, y = target, x = 'Mixed')\n",
    "    ax.set_xlabel(\"Entropy > \"+str(entropy_threshold))\n",
    "    ax.set_ylabel(target)\n",
    "    ax.set_title(\"Clade size > \"+str(X), fontsize = 10)\n",
    "\n",
    "    ax.axhline(mean_hd_all_clades)\n",
    "\n",
    "    #ax.set_ylim(0,1)\n",
    "    plt.savefig(\"figures/\"+target+\"_distribution_\"+str(X)+\".pdf\", bbox_inches='tight')\n",
    "\n",
    "    sns.violinplot(data = df_clade_hd, y = target, x = 'Mixed')\n",
    "    print(stats.mannwhitneyu(df_clade_hd[df_clade_hd[\"Mixed\"]==True]['meanhd'], df_clade_hd[df_clade_hd[\"Mixed\"]==False]['meanhd']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def seqdist(str1, str2):\n",
    "    count = 0\n",
    "    for i in range(len(str1)):\n",
    "        if str1[i]!=str2[i]:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "parentname_list = list(name2parentseq.keys())\n",
    "new_parentname_list = []\n",
    "\n",
    "for parentname in parentname_list:\n",
    "    seq = name2parentseq[parentname]\n",
    "    seq = seq.replace(\"-\", \"\")\n",
    "    if (len(seq) > 150):\n",
    "        new_parentname_list.append(parentname)\n",
    "parentname_list = new_parentname_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dist_matrix = np.zeros((len(parentname_list), len(parentname_list)))\n",
    "for i, parent_i in enumerate(parentname_list):\n",
    "    for j, parent_j in enumerate(parentname_list):\n",
    "        dist_matrix[i,j] = seqdist(name2parentseq[parent_i], name2parentseq[parent_j])\n",
    "\n",
    "df_dist_matrix = pd.DataFrame(dist_matrix, index = parentname_list, columns = parentname_list)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(100,100))\n",
    "\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax2 = fig.add_axes([1.0,0.1,0.05,0.2])\n",
    "sns.heatmap(df_dist_matrix, cmap = 'cividis_r', ax = ax, cbar_ax = ax2)\n",
    "\n",
    "plt.savefig(\"figures/heatmap_parent_dist_matrix.pdf\", bbox_inches='tight', )\n",
    "\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(100,100))\n",
    "sns.clustermap(df_dist_matrix, cmap = 'cividis_r')\n",
    "\n",
    "plt.savefig(\"figures/clustermap_parent_dist_matrix.pdf\", bbox_inches='tight', )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "cladename = \"Clade3977\"\n",
    "clade_random_sample = random.sample(list(df_merge[df_merge['Clade']==cladename].Tip), 10)\n",
    "name_dist_list = []\n",
    "for seqname in parentname_list:\n",
    "    for tipname in clade_random_sample:\n",
    "        name_dist_list.append([seqname, tipname, seqdist(name2parentseq[seqname], name2seq[tipname])])\n",
    "df_name_dist           = pd.DataFrame(name_dist_list, columns = ['name', 'tipname', 'dist'])\n",
    "df_name_dist['Well']   = [name.split(\"_\")[0] for name in df_name_dist['name']]\n",
    "#df_name_dist_mean_tips = df_name_dist.groupby('Well').mean()\n",
    "df_name_dist_mean_tips = df_name_dist.groupby('name').mean()\n",
    "#df_name_dist_mean_tips.sort_values(\"Well\")\n",
    "fig = plt.figure(figsize=(15,2))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax.set_xlim(0, len(df_name_dist_mean_tips.index)+1)\n",
    "ax.tick_params(axis='x',rotation=90,labelsize=3)\n",
    "ax.bar(x = df_name_dist_mean_tips.index, height = df_name_dist_mean_tips['dist'])\n",
    "ax.set_ylabel(\"Mean Hamming Distance\")\n",
    "ax.set_xlabel(\"Parental sequence\")\n",
    "\n",
    "ax.set_title(cladename)\n",
    "plt.savefig(\"figures/parent_MHD_\"+cladename+\".pdf\", bbox_inches='tight', )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "cladename = \"Clade3977\"\n",
    "clade_random_sample = random.sample(list(df_merge[df_merge['Clade']==cladename].Tip), 10)\n",
    "name_dist_list = []\n",
    "for seqname in parentname_list:\n",
    "    for tipname in clade_random_sample:\n",
    "        name_dist_list.append([seqname, tipname, seqdist(name2parentseq[seqname], name2seq[tipname])])\n",
    "df_name_dist           = pd.DataFrame(name_dist_list, columns = ['name', 'tipname', 'dist'])\n",
    "df_name_dist['Well']   = [name.split(\"_\")[0] for name in df_name_dist['name']]\n",
    "#df_name_dist_mean_tips = df_name_dist.groupby('Well').mean()\n",
    "df_name_dist_mean_tips = df_name_dist.groupby('name').mean()\n",
    "#list(df_name_dist_mean_tips['dist'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "threshold = 6\n",
    "\n",
    "dist_matrix = []\n",
    "\n",
    "messy_clade_list = list(set(df_merge[df_merge['Entropy']>threshold].Clade))\n",
    "\n",
    "for cladename in messy_clade_list:\n",
    "\n",
    "    clade_random_sample = random.sample(list(df_merge[df_merge['Clade']==cladename].Tip), 10)\n",
    "    name_dist_list = []\n",
    "    for seqname in parentname_list:\n",
    "        for tipname in clade_random_sample:\n",
    "            name_dist_list.append([seqname, tipname, seqdist(name2parentseq[seqname], name2seq[tipname])])\n",
    "    df_name_dist           = pd.DataFrame(name_dist_list, columns = ['name', 'tipname', 'dist'])\n",
    "    df_name_dist['Well']   = [name.split(\"_\")[0] for name in df_name_dist['name']]\n",
    "    #df_name_dist_mean_tips = df_name_dist.groupby('Well').mean()\n",
    "    df_name_dist_mean_tips = df_name_dist.groupby('name').mean()\n",
    "    dist_matrix.append(list(df_name_dist_mean_tips['dist']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_clade_parent = pd.DataFrame(dist_matrix, index = messy_clade_list, columns = parentname_list)\n",
    "\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax2 = fig.add_axes([1.0,0.1,0.05,0.2])\n",
    "sns.heatmap(df_clade_parent, cmap ='cividis_r', ax =ax, cbar_ax = ax2)\n",
    "plt.savefig(\"figures/messyclade_parent.pdf\", bbox_inches='tight', )\n",
    "plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# E4_1と各配列の距離を計算\n",
    "\n",
    "name_dist_list = []\n",
    "records = SeqIO.parse(gzip.open(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0150/from_idenken/fractalin.bcat.fa.gz\",'rt'), 'fasta')\n",
    "name2seq = {}\n",
    "for record in records:\n",
    "    name2seq[record.name] = str(record.seq)\n",
    "    if (record.name != \"root\"):\n",
    "        seq  = str(record.seq)\n",
    "        name_dist_list.append([record.name, seqdist(seq, name2parentseq[\"E4_1\"])])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_name_dist_E4_1 = pd.DataFrame(name_dist_list, columns = ['Tip', 'Distance_to_E4_1'])\n",
    "df_name_dist_E4_1_merge = pd.merge(df_merge, df_name_dist_E4_1 , on = 'Tip')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_merge['Well'] = [tip.split(\"_\")[3] for tip in df_merge['Tip']]\n",
    "\n",
    "fig = plt.figure(figsize=(2,1))\n",
    "for i, idx_alphabet in enumerate(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']):\n",
    "    for j in range(12):\n",
    "        well = idx_alphabet + str(j+1)\n",
    "\n",
    "        df_merge_ext = df_name_dist_E4_1_merge[df_merge['Well'] == well]\n",
    "        ax = fig.add_axes([0.1+i*1.2,0.1+j*1.4,0.8,0.8])\n",
    "\n",
    "        ax.hist(df_merge_ext['Distance_to_E4_1'], range = (0, 50), bins = 51)\n",
    "\n",
    "        df_merge_ext_messy = df_merge_ext[df_merge_ext['Entropy'] > 1]\n",
    "\n",
    "        ax.hist(df_merge_ext_messy['Distance_to_E4_1'], range = (0, 50), bins = 51)\n",
    "\n",
    "        ax.set_title(well, fontsize = 10) \n",
    "        if (j == 0): ax.set_xlabel(\"Distance to E4_1\")\n",
    "        if (i == 0): ax.set_ylabel(\"# seq\")\n",
    "        ax.set_xlim(0,50)\n",
    "        #ax.set_ylim(1,300000)\n",
    "plt.savefig(\"figures/Dist_to_E4_1_wells.pdf\", bbox_inches='tight')\n",
    "plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tree = Phylo.read(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0150/from_yusuke/FRACTALout.ext.nwk\", 'newick')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "old_tip_names = set([old_tip.name for old_tip in tree.get_terminals()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_old_tips = pd.read_table(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0150/from_yusuke/col1Merged.col2Previous.tsv\", names = [\"Tip\", \"Old_Tip\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_old_tips[\"included\"] = [True if (name in old_tip_names) else False for name in df_old_tips[\"Old_Tip\"]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_old_tips_included = pd.merge(df_merge, df_old_tips, on ='Tip')\n",
    "df_old_tips_included"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(2,2))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "\n",
    "sns.violinplot(data = df_old_tips_included, y = 'Entropy', x = 'included')\n",
    "ax.set_xlabel(\"Included in the previous version\")\n",
    "ax.set_ylabel(\"Entropy\")\n",
    "#ax.set_ylim(0,1)\n",
    "plt.savefig(\"figures/tree_included.pdf\", bbox_inches='tight')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_old_tips_included.sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}
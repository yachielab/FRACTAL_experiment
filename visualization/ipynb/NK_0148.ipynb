{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0a1e5715f1a9b8bb34f63c3d966d40c5c588b4d4fc6358b5bb274d07955f54348",
   "display_name": "Python 3.9.1 64-bit ('fractal': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Bio import Phylo, SeqIO\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "import statistics as stat\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import gzip"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mpl.rcParams['font.family']       = 'Helvetica'\n",
    "mpl.rcParams['font.sans-serif']   = [\"Helvetica\",\"Arial\",\"DejaVu Sans\",\"Lucida Grande\",\"Verdana\"]\n",
    "mpl.rcParams['figure.figsize']    = [4,3]\n",
    "mpl.rcParams['font.size']         = 9\n",
    "mpl.rcParams[\"axes.labelcolor\"]   = \"#000000\"\n",
    "mpl.rcParams[\"axes.linewidth\"]    = 1.0 \n",
    "mpl.rcParams[\"xtick.major.width\"] = 1.0\n",
    "mpl.rcParams[\"ytick.major.width\"] = 1.0\n",
    "cmap1 = plt.cm.tab10\n",
    "cmap2 = plt.cm.Set3  \n",
    "colors1 = [cmap1(i) for i in range(0,10)]\n",
    "colors2 = [cmap2(i) for i in range(0,12)] \n",
    "plt.style.use('default')\n",
    "\n",
    "def generate_cmap(colors):\n",
    "    color_list = []\n",
    "    values = range(len(colors))\n",
    "    vmax   = int(np.max(values))\n",
    "    for v, c in enumerate(colors):\n",
    "        color_list.append( (v*1.0/ vmax, c) )\n",
    "    return LinearSegmentedColormap.from_list('custom_cmap', color_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.chdir(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148\")\n",
    "try:\n",
    "    os.mkdir(\"figures\")\n",
    "except:\n",
    "    None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# L\n",
    "\n",
    "def L_read_data(csvfile):\n",
    "    data = pd.read_csv(csvfile, names = [\"FRACTAL_ID\", \"SIM_ID\", \"Method\", \"Mode\", \"Nseq\", \"mu\", \"alpha\", \"L\", \"sigma\", \"Memory\", \"Memory_unit\", \"Run time\", \"Time_unit\", \"Ntips\", \"NRFD\"])\n",
    "    data = data.sort_values(\"FRACTAL_ID\")\n",
    "    data[\"Coverage\"] = data[\"Ntips\"] / data[\"Nseq\"] * 100\n",
    "    data[\"Accuracy\"] = (1 - data[\"NRFD\"]) * 100\n",
    "    return data\n",
    "\n",
    "for method in [\"rapidnjNJ\", \"raxmlMP\", \"fasttreeML\"]:\n",
    "    data_fractal = L_read_data(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/L/result.\"+method+\"_fractal.csv\")\n",
    "    data_original = L_read_data(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/L/result.\"+method+\"_original.csv\")\n",
    "\n",
    "    df_merged = pd.merge(data_fractal.loc[:,['L','Accuracy']], data_original.loc[:,['L','Accuracy']], on = 'L')\n",
    "    df_merged = df_merged.rename(columns = {'Accuracy_x':'Accuracy_fractal', 'Accuracy_y':'Accuracy_original'})\n",
    "    df_merged['Accuracy_diff'] = df_merged['Accuracy_fractal'] - df_merged['Accuracy_original']\n",
    "    print(method, \"The maximum length for which the accuracy of FRACTAL was >5% smaller than original:\", max(df_merged[df_merged['Accuracy_diff'] < -5].L))\n",
    "\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    ax = fig.add_axes([0.1,0.1,0.8,0.5])\n",
    "    i=0\n",
    "    ax.set_title(method)\n",
    "    #ax.set_xlabel(\"$L$\")\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    ax.set_xlim(left=-150, right=1650) \n",
    "    ax.set_ylim(-5,105)\n",
    "    ax.scatter(x=data_original['L'],y=data_original['Accuracy'], label='without_FRACTAL',color='#FFD479', s = 7)\n",
    "    ax.scatter(x=data_fractal['L'],y=data_fractal['Accuracy'], label='with_FRACTAL',color='#73CBD6', s = 7)\n",
    "    ax.spines[\"top\"].set_color(\"none\")\n",
    "    ax.spines[\"right\"].set_color(\"none\")\n",
    "    ax.spines[\"bottom\"].set_color(\"none\")\n",
    "    ax.tick_params(bottom= False, labelbottom=False)\n",
    "\n",
    "    ax2 = fig.add_axes([0.1,0.1-0.25,0.8,0.20])\n",
    "    ax2.set_xlabel(\"$L$\")\n",
    "    ax2.set_ylabel('Coverage (%)')\n",
    "    ax2.bar(x=data_fractal['L'],height=data_fractal['Coverage'], color='#429468', width=int(1500/300),)\n",
    "    ax2.set_title('')\n",
    "    ax2.set_xlim(left=-150, right=1650) \n",
    "    ax2.set_ylim(bottom=-5, top=105) \n",
    "    ax2.spines[\"top\"].set_color(\"none\")\n",
    "    ax2.spines[\"right\"].set_color(\"none\")\n",
    "\n",
    "\n",
    "    fig.savefig(\"figures/NK_0148_L_\"+method+\".pdf\",bbox_inches=\"tight\")\n",
    "    #plt.show()\n",
    "    plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# mu - alpha\n",
    "method = \"fasttreeML\"\n",
    "csvfile = \"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/mu_alpha/result.\"+method+\"_fractal.csv\"\n",
    "\n",
    "def mu_alpha_read_data(csvfile):\n",
    "    data = pd.read_csv(csvfile, names = [\"FRACTAL_ID\", \"SIM_ID\", \"Method\", \"Mode\", \"Nseq\", \"mu\", \"alpha\", \"L\", \"sigma\", \"Memory\", \"Memory_unit\", \"Run time\", \"Time_unit\", \"Ntips\", \"NRFD\"])\n",
    "    data = data.sort_values(\"FRACTAL_ID\")\n",
    "    data[\"Coverage\"] = data[\"Ntips\"] / data[\"Nseq\"] * 100\n",
    "    data[\"Accuracy\"] = (1 - data[\"NRFD\"]) * 100\n",
    "    \n",
    "    mu_list = list(sorted(set(list(data['mu']))))\n",
    "    alpha_list = list(reversed(sorted(set(list(data['alpha'])))))\n",
    "\n",
    "    mu2colidx    = {mu: idx    for idx, mu    in enumerate(mu_list   )}\n",
    "    alpha2rowidx = {alpha: idx for idx, alpha in enumerate(alpha_list)}\n",
    "    mtx_accuracy = np.zeros((len(alpha_list), len(mu_list))); mtx_accuracy[:,:] = np.nan\n",
    "    mtx_coverage = np.zeros((len(alpha_list), len(mu_list))); mtx_coverage[:,:] = np.nan\n",
    "    for mu, alpha, accuracy, coverage in zip(data['mu'], data['alpha'], data['Accuracy'], data['Coverage']):\n",
    "        mtx_accuracy[alpha2rowidx[alpha]][mu2colidx[mu]] = accuracy\n",
    "        mtx_coverage[alpha2rowidx[alpha]][mu2colidx[mu]] = coverage\n",
    "    \n",
    "    df_accuracy = pd.DataFrame(mtx_accuracy, index = alpha_list, columns = mu_list)\n",
    "    df_coverage = pd.DataFrame(mtx_coverage, index = alpha_list, columns = mu_list)\n",
    "    return df_accuracy, df_coverage"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for method in [\"rapidnjNJ\", \"raxmlMP\", \"fasttreeML\"]:\n",
    "    df_accuracy_fractal, df_coverage_fractal   = mu_alpha_read_data(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/mu_alpha/result.\"+method+\"_fractal.csv\")\n",
    "    df_accuracy_original, df_coverage_original = mu_alpha_read_data(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/mu_alpha/result.\"+method+\"_original.csv\")\n",
    "    df_accuracy_diff = df_accuracy_fractal - df_accuracy_original\n",
    "    for name, cmap, vmin, vmax, df in [(\"accuracy_original\", 'plasma', 50, 100, df_accuracy_original), (\"accuracy_fractal\", 'plasma', 50, 100, df_accuracy_fractal), (\"accuracy_diff\", 'coolwarm_r', -20, 20, df_accuracy_diff), (\"coverage_fractal\", 'RdPu_r', 90, 100, df_coverage_fractal)]:\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        ax  = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "        ax2 = fig.add_axes([0.1 + 0.9, 0.45,0.4,0.1])\n",
    "        ax.patch.set_facecolor('grey')\n",
    "        ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "        sns.heatmap(df, cmap=cmap, ax=ax, cbar_ax=ax2, cbar_kws={'orientation': 'horizontal'}, vmin=vmin, vmax=vmax)\n",
    "        ax.set_xticks([4.5, 9.5, 14.5, 19.5, 24.5])\n",
    "        ax.set_xticklabels([1.0,2.0,3.0,4.0,5.0])\n",
    "        ax.set_yticks(23-np.array([2.5, 7.5, 12.5, 17.5, 22.5]))\n",
    "        ax.set_yticklabels([0.20, 0.63, 2.00, 6.31, 19.95])\n",
    "        ax.set_title(method+\"_\"+name)\n",
    "        ax.set_xlabel(\"$\\mu$\")\n",
    "        ax.set_ylabel(\"$\\\\alpha$\")\n",
    "        plt.savefig(\"figures/NK_0148_mu_alpha_\"+method+\"_\"+name+\".pdf\", bbox_inches='tight')\n",
    "        plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sigma - mu\n",
    "method = \"fasttreeML\"\n",
    "csvfile = \"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/mu_alpha/result.\"+method+\"_fractal.csv\"\n",
    "\n",
    "def sigma_mu_read_data(csvfile):\n",
    "    data = pd.read_csv(csvfile, names = [\"FRACTAL_ID\", \"SIM_ID\", \"Method\", \"Mode\", \"Nseq\", \"mu\", \"alpha\", \"L\", \"sigma\", \"Memory\", \"Memory_unit\", \"Run time\", \"Time_unit\", \"Ntips\", \"NRFD\"])\n",
    "    data = data.sort_values(\"FRACTAL_ID\")\n",
    "    data[\"Coverage\"] = data[\"Ntips\"] / data[\"Nseq\"] * 100\n",
    "    data[\"Accuracy\"] = (1 - data[\"NRFD\"]) * 100\n",
    "    \n",
    "    mu_list = list(sorted(set(list(data['mu']))))\n",
    "    sigma_list_pre = list(reversed(sorted(set(list(data['sigma'])))))\n",
    "    \n",
    "    sigma_list = []\n",
    "    for sigma in sigma_list_pre:\n",
    "        if (sigma < 3.1):\n",
    "            sigma_list.append(sigma)\n",
    "\n",
    "    mu2colidx    = {mu: idx    for idx, mu    in enumerate(mu_list   )}\n",
    "    sigma2rowidx = {sigma: idx for idx, sigma in enumerate(sigma_list)}\n",
    "    mtx_accuracy = np.zeros((len(sigma_list), len(mu_list))); mtx_accuracy[:,:] = np.nan\n",
    "    mtx_coverage = np.zeros((len(sigma_list), len(mu_list))); mtx_coverage[:,:] = np.nan\n",
    "    for mu, sigma, accuracy, coverage in zip(data['mu'], data['sigma'], data['Accuracy'], data['Coverage']):\n",
    "        try:\n",
    "            mtx_accuracy[sigma2rowidx[sigma]][mu2colidx[mu]] = accuracy\n",
    "            mtx_coverage[sigma2rowidx[sigma]][mu2colidx[mu]] = coverage\n",
    "        except:\n",
    "            None\n",
    "            #print(mu, sigma)\n",
    "    \n",
    "    df_accuracy = pd.DataFrame(mtx_accuracy, index = sigma_list, columns = mu_list)\n",
    "    df_coverage = pd.DataFrame(mtx_coverage, index = sigma_list, columns = mu_list)\n",
    "    return df_accuracy, df_coverage"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for method in [\"rapidnjNJ\", \"raxmlMP\", \"fasttreeML\"]:\n",
    "    df_accuracy_fractal_1, df_coverage_fractal_1   = sigma_mu_read_data(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/sigma_mu/result.\"+method+\"_fractal.csv\")\n",
    "    df_accuracy_original_1, df_coverage_original_1 = sigma_mu_read_data(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/sigma_mu/result.\"+method+\"_original.csv\")\n",
    "\n",
    "    df_accuracy_fractal_2, df_coverage_fractal_2   = sigma_mu_read_data(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/sigma_mu/result.\"+method+\"_fractal.2.csv\")\n",
    "    df_accuracy_original_2, df_coverage_original_2 = sigma_mu_read_data(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/sigma_mu/result.\"+method+\"_original.2.csv\")\n",
    "\n",
    "    df_accuracy_fractal_max = np.maximum(df_accuracy_fractal_1.replace(np.nan, -1), df_accuracy_fractal_2.replace(np.nan, -1)).replace(-1, np.nan)\n",
    "    df_coverage_fractal_max = np.maximum(df_coverage_fractal_1.replace(np.nan, -1), df_coverage_fractal_2.replace(np.nan, -1)).replace(-1, np.nan)\n",
    "\n",
    "    for df_accuracy_fractal, df_coverage_fractal, df_accuracy_original, df_coverage_original, df_label in [(df_accuracy_fractal_1, df_coverage_fractal_1, df_accuracy_original_1, df_coverage_original_1, \"1\"), (df_accuracy_fractal_2, df_coverage_fractal_2, df_accuracy_original_2, df_coverage_original_2, \"2\"), (df_accuracy_fractal_max, df_coverage_fractal_max, df_accuracy_original_2, df_coverage_original_2, \"max\")]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df_accuracy_diff = df_accuracy_fractal - df_accuracy_original\n",
    "        for name, cmap, vmin, vmax, df in [(\"accuracy_original\", 'plasma', 50, 100, df_accuracy_original), (\"accuracy_fractal\", 'plasma', 50, 100, df_accuracy_fractal), (\"accuracy_diff\", 'coolwarm_r', -40, 40, df_accuracy_diff), (\"coverage_fractal\", 'RdPu_r', 0, 100, df_coverage_fractal)]:\n",
    "            fig = plt.figure(figsize=(3,3))\n",
    "            ax  = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "            ax2 = fig.add_axes([0.1 + 0.9, 0.45,0.4,0.1])\n",
    "            ax.patch.set_facecolor('grey')\n",
    "            ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "            sns.heatmap(df, cmap=cmap, ax=ax, cbar_ax=ax2, cbar_kws={'orientation': 'horizontal'}, vmin=vmin, vmax=vmax)\n",
    "            #ax.set_xticks([4.5, 9.5, 14.5, 19.5, 24.5])\n",
    "            #ax.set_xticklabels([1.0,2.0,3.0,4.0,5.0])\n",
    "            #ax.set_yticks(23-np.array([2.5, 7.5, 12.5, 17.5, 22.5]))\n",
    "            #ax.set_yticklabels([0.20, 0.63, 2.00, 6.31, 19.95])\n",
    "            ax.set_title(method+\"_\"+name+\"_\"+df_label)\n",
    "            ax.set_xlabel(\"$\\mu$\")\n",
    "            ax.set_ylabel(\"$\\\\sigma$\")\n",
    "            ax.set_xticks([0.5,5.5,10.5,15.5,20.5])\n",
    "            ax.set_xticklabels(['0.01','0.032','0.10','0.32','1.0'])\n",
    "            ax.set_yticks([0.5, 10.5, 20.5, 30.5])\n",
    "            ax.set_yticklabels(['3.0','2.0','1.0','0.0'])\n",
    "            plt.savefig(\"figures/NK_0148_sigma_mu_\"+method+\"_\"+name+\"_\"+df_label+\".pdf\", bbox_inches='tight')\n",
    "            plt.close()"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# mu - alpha varying FRACTAL parameters\n",
    "def mu_alpha_fractal(csvfile):\n",
    "    data    = pd.read_csv(csvfile, names = [\"TASK_ID\", \"SIM_ID\", \"Method\", \"None\", \"Nseq\", \"Subsample\", \"Threshold\", \"Memory\", \"Memory_unit\", \"Time\", \"Time_unit\", \"Ntips\", \"NRFD\"])\n",
    "    data    = data.sort_values(\"Threshold\", ascending = False)\n",
    "\n",
    "    data[\"Coverage\"] = data[\"Ntips\"] / data[\"Nseq\"] * 100\n",
    "    data[\"Accuracy\"] = (1 - data[\"NRFD\"]) * 100\n",
    "        \n",
    "    subsample_list = list(sorted(set(list(data['Subsample']))))\n",
    "    threshold_list = list(reversed(sorted(set(list(data['Threshold'])))))\n",
    "\n",
    "    subsample2colidx = {subsample: idx for idx, subsample in enumerate(subsample_list)}\n",
    "    threshold2rowidx = {threshold: idx for idx, threshold in enumerate(threshold_list)}\n",
    "    mtx_accuracy = np.zeros((len(threshold_list), len(subsample_list))); mtx_accuracy[:,:] = np.nan\n",
    "    mtx_coverage = np.zeros((len(threshold_list), len(subsample_list))); mtx_coverage[:,:] = np.nan\n",
    "    mtx_time     = np.zeros((len(threshold_list), len(subsample_list))); mtx_coverage[:,:] = np.nan\n",
    "    mtx_memory   = np.zeros((len(threshold_list), len(subsample_list))); mtx_coverage[:,:] = np.nan\n",
    "    mtx_background = np.zeros((len(threshold_list), len(subsample_list))); mtx_coverage[:,:] = np.nan\n",
    "    for subsample, threshold, accuracy, coverage, time, memory in zip(data['Subsample'], data['Threshold'], data['Accuracy'], data['Coverage'], data['Time'], data['Memory']):\n",
    "        mtx_accuracy[threshold2rowidx[threshold]][subsample2colidx[subsample]] = accuracy\n",
    "        mtx_coverage[threshold2rowidx[threshold]][subsample2colidx[subsample]] = coverage\n",
    "        mtx_time    [threshold2rowidx[threshold]][subsample2colidx[subsample]] = time\n",
    "        mtx_memory  [threshold2rowidx[threshold]][subsample2colidx[subsample]] = memory\n",
    "\n",
    "    for threshold in threshold_list:\n",
    "        mtx_time_ratio   = np.log2(mtx_time / sum(mtx_time[threshold2rowidx[36204]])*len(mtx_time[threshold2rowidx[36204]]))\n",
    "        mtx_memory_ratio = np.log2(mtx_memory / sum(mtx_memory[threshold2rowidx[36204]])*len(mtx_memory[threshold2rowidx[36204]]))\n",
    "\n",
    "    original_ave_accuracy = sum(mtx_accuracy[threshold2rowidx[36204]]) / len(mtx_accuracy[threshold2rowidx[36204]])\n",
    "\n",
    "    for subsample in subsample_list:\n",
    "        for threshold in threshold_list:\n",
    "            mtx_background[threshold2rowidx[threshold]][subsample2colidx[subsample]] = (1 if (subsample > threshold) else 0)\n",
    "\n",
    "            #if (mtx_accuracy[threshold2rowidx[threshold]][subsample2colidx[subsample]] - original_ave_accuracy < -5)):\n",
    "            #    mtx_time_ratio[threshold2rowidx[threshold]][subsample2colidx[subsample]] = np.nan\n",
    "            #    mtx_memory_ratio[threshold2rowidx[threshold]][subsample2colidx[subsample]] = np.nan\n",
    "\n",
    "    df_accuracy = pd.DataFrame(mtx_accuracy, index = threshold_list, columns = subsample_list)\n",
    "    df_coverage = pd.DataFrame(mtx_coverage, index = threshold_list, columns = subsample_list)\n",
    "    df_time     = pd.DataFrame(mtx_time_ratio, index = threshold_list, columns = subsample_list)\n",
    "    df_memory   = pd.DataFrame(mtx_memory_ratio, index = threshold_list, columns = subsample_list)\n",
    "    df_background = pd.DataFrame(mtx_background, index = threshold_list, columns = subsample_list)\n",
    "\n",
    "    return df_accuracy, df_coverage, df_time, df_memory, df_background"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### To be deleted ###\n",
    "# mu - alpha varying FRACTAL parameters\n",
    "def mu_alpha_fractal(csvfile):\n",
    "    data    = pd.read_csv(csvfile, names = [\"TASK_ID\", \"SIM_ID\", \"Method\", \"None\", \"Nseq\", \"Subsample\", \"Threshold\", \"Memory\", \"Memory_unit\", \"Time\", \"Time_unit\", \"Ntips\", \"NRFD\"])\n",
    "    data    = data.sort_values(\"Threshold\", ascending = False)\n",
    "\n",
    "    data[\"Coverage\"] = data[\"Ntips\"] / data[\"Nseq\"] * 100\n",
    "    data[\"Accuracy\"] = (1 - data[\"NRFD\"]) * 100\n",
    "        \n",
    "    subsample_list = list(sorted(set(list(data['Subsample']))))\n",
    "    threshold_list = list(reversed(sorted(set(list(data['Threshold'])))))\n",
    "\n",
    "    subsample2colidx = {subsample: idx for idx, subsample in enumerate(subsample_list)}\n",
    "    threshold2rowidx = {threshold: idx for idx, threshold in enumerate(threshold_list)}\n",
    "    mtx_accuracy = np.zeros((len(threshold_list), len(subsample_list))); mtx_accuracy[:,:] = np.nan\n",
    "    mtx_coverage = np.zeros((len(threshold_list), len(subsample_list))); mtx_coverage[:,:] = np.nan\n",
    "    mtx_time     = np.zeros((len(threshold_list), len(subsample_list))); mtx_coverage[:,:] = np.nan\n",
    "    mtx_memory   = np.zeros((len(threshold_list), len(subsample_list))); mtx_coverage[:,:] = np.nan\n",
    "    mtx_background = np.zeros((len(threshold_list), len(subsample_list))); mtx_coverage[:,:] = np.nan\n",
    "    for subsample, threshold, accuracy, coverage, time, memory in zip(data['Subsample'], data['Threshold'], data['Accuracy'], data['Coverage'], data['Time'], data['Memory']):\n",
    "        mtx_accuracy[threshold2rowidx[threshold]][subsample2colidx[subsample]] = accuracy\n",
    "        mtx_coverage[threshold2rowidx[threshold]][subsample2colidx[subsample]] = coverage\n",
    "        mtx_time    [threshold2rowidx[threshold]][subsample2colidx[subsample]] = time\n",
    "        mtx_memory  [threshold2rowidx[threshold]][subsample2colidx[subsample]] = memory\n",
    "\n",
    "    #for i in range(len(mtx_time)):\n",
    "    #    for j in range(len(mtx_time[0])):\n",
    "    #        if mtx_time[i][j] == 0:\n",
    "    #            print(i,j) \n",
    "\n",
    "    for threshold in threshold_list:\n",
    "        mtx_time_ratio   = np.log2(mtx_time / sum(mtx_time[threshold2rowidx[36204]])*len(mtx_time[threshold2rowidx[36204]]))\n",
    "        mtx_memory_ratio = np.log2(mtx_memory / sum(mtx_memory[threshold2rowidx[36204]])*len(mtx_memory[threshold2rowidx[36204]]))\n",
    "\n",
    "    original_ave_accuracy = sum(mtx_accuracy[threshold2rowidx[36204]]) / len(mtx_accuracy[threshold2rowidx[36204]])\n",
    "\n",
    "    for subsample in subsample_list:\n",
    "        for threshold in threshold_list:\n",
    "            mtx_background[threshold2rowidx[threshold]][subsample2colidx[subsample]] = (1 if (subsample > threshold) else 0)\n",
    "\n",
    "            if (mtx_accuracy[threshold2rowidx[threshold]][subsample2colidx[subsample]] - original_ave_accuracy < -5):\n",
    "                mtx_time_ratio[threshold2rowidx[threshold]][subsample2colidx[subsample]] = np.nan\n",
    "                mtx_memory_ratio[threshold2rowidx[threshold]][subsample2colidx[subsample]] = np.nan\n",
    "\n",
    "    df_accuracy = pd.DataFrame(mtx_accuracy, index = threshold_list, columns = subsample_list)\n",
    "    df_coverage = pd.DataFrame(mtx_coverage, index = threshold_list, columns = subsample_list)\n",
    "    df_time     = pd.DataFrame(mtx_time_ratio, index = threshold_list, columns = subsample_list)\n",
    "    df_memory   = pd.DataFrame(mtx_memory_ratio, index = threshold_list, columns = subsample_list)\n",
    "    df_background = pd.DataFrame(mtx_background, index = threshold_list, columns = subsample_list)\n",
    "\n",
    "    return df_accuracy, df_coverage, df_time, df_memory, df_background\n",
    "\n",
    "method = \"raxmlMP\"\n",
    "dataset = \"600\"\n",
    "for method in [\"rapidnjNJ\", \"raxmlMP\", \"fasttreeML\"]:\n",
    "    for dataset in [\"312\", \"600\"]:\n",
    "\n",
    "        df_accuracy, df_coverage, df_time, df_memory, df_background = mu_alpha_fractal(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/mu_alpha_fractal_param/result.\"+method+\".\"+dataset+\".csv\")\n",
    "\n",
    "        title = method + \"_\" + dataset\n",
    "\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        ax1 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"a\")\n",
    "        ax2 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"b\")\n",
    "        ax2.patch.set_alpha(0.0)\n",
    "        ax1.set_title(title,fontsize=10)\n",
    "        ax1.patch.set_facecolor('grey')\n",
    "        sns.heatmap(df_background, ax=ax1, cmap=generate_cmap(['#00008B','#bbbbbb']),cbar_kws={\"ticks\":[]},cbar=False)\n",
    "        sns.heatmap(df_accuracy  , ax=ax2, cmap='plasma',vmin=0, vmax=100,cbar=False)\n",
    "        plt.savefig(\"figures_test/NK_0148_a_accuracy_\"+title+\".pdf\", bbox_inches = 'tight')\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        ax1 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"a\")\n",
    "        ax2 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"b\")\n",
    "        ax2.patch.set_alpha(0.0)\n",
    "        ax1.set_title(title,fontsize=10)\n",
    "        ax1.patch.set_facecolor('grey')\n",
    "        sns.heatmap(df_background, ax=ax1,cmap=generate_cmap(['#00008B','#bbbbbb']),cbar_kws={\"ticks\":[]},cbar=False)\n",
    "        sns.heatmap(df_coverage  , ax=ax2,cmap='RdPu_r',vmin=0, vmax=100,cbar=False)\n",
    "        plt.savefig(\"figures_test/NK_0148_b_coverage_\"+title+\".pdf\", bbox_inches = 'tight')\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        ax1 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"a\")\n",
    "        ax2 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"b\")\n",
    "        ax2.patch.set_alpha(0.0)\n",
    "        ax1.set_title(title,fontsize=10)\n",
    "        ax1.patch.set_facecolor('grey')\n",
    "        sns.heatmap(df_background, ax=ax1,cmap=generate_cmap(['#DDDDDD','#bbbbbb']),cbar_kws={\"ticks\":[]},cbar=False)\n",
    "        sns.heatmap(df_time  , ax=ax2,cmap='Spectral_r',vmin=-1, vmax=1,cbar=False)\n",
    "        plt.savefig(\"figures_test/NK_0148_c_runtime_\"+title+\".pdf\", bbox_inches = 'tight')\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        ax1 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"a\")\n",
    "        ax2 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"b\")\n",
    "        ax2.patch.set_alpha(0.0)\n",
    "        ax1.set_title(title,fontsize=10)\n",
    "        ax1.patch.set_facecolor('grey')\n",
    "        sns.heatmap(df_background, ax=ax1,cmap=generate_cmap(['#DDDDDD','#bbbbbb']),cbar_kws={\"ticks\":[]},cbar=False)\n",
    "        sns.heatmap(df_memory  , ax=ax2,cmap='Spectral_r',vmin=-1, vmax=1,cbar=False)\n",
    "        plt.savefig(\"figures_test/NK_0148_d_memory_\"+title+\".pdf\", bbox_inches = 'tight')\n",
    "        #plt.show()\n",
    "        plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "method = \"raxmlMP\"\n",
    "dataset = \"600\"\n",
    "for method in [\"rapidnjNJ\", \"raxmlMP\", \"fasttreeML\"]:\n",
    "    for dataset in [\"312\", \"600\"]:\n",
    "\n",
    "        df_accuracy, df_coverage, df_time, df_memory, df_background = mu_alpha_fractal(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/mu_alpha_fractal_param/result.\"+method+\".\"+dataset+\".csv\")\n",
    "\n",
    "        title = method + \"_\" + dataset\n",
    "\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        ax1 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"a\")\n",
    "        ax2 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"b\")\n",
    "        ax2.patch.set_alpha(0.0)\n",
    "        ax1.set_title(title,fontsize=10)\n",
    "        ax1.patch.set_facecolor('grey')\n",
    "        sns.heatmap(df_background, ax=ax1, cmap=generate_cmap(['#00008B','#bbbbbb']),cbar_kws={\"ticks\":[]},cbar=False)\n",
    "        sns.heatmap(df_accuracy  , ax=ax2, cmap='plasma',vmin=0, vmax=100,cbar=False)\n",
    "        plt.savefig(\"figures/NK_0148_a_accuracy_\"+title+\".pdf\", bbox_inches = 'tight')\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        ax1 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"a\")\n",
    "        ax2 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"b\")\n",
    "        ax2.patch.set_alpha(0.0)\n",
    "        ax1.set_title(title,fontsize=10)\n",
    "        ax1.patch.set_facecolor('grey')\n",
    "        sns.heatmap(df_background, ax=ax1,cmap=generate_cmap(['#00008B','#bbbbbb']),cbar_kws={\"ticks\":[]},cbar=False)\n",
    "        sns.heatmap(df_coverage  , ax=ax2,cmap='RdPu_r',vmin=0, vmax=100,cbar=False)\n",
    "        plt.savefig(\"figures/NK_0148_b_coverage_\"+title+\".pdf\", bbox_inches = 'tight')\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        ax1 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"a\")\n",
    "        ax2 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"b\")\n",
    "        ax2.patch.set_alpha(0.0)\n",
    "        ax1.set_title(title,fontsize=10)\n",
    "        ax1.patch.set_facecolor('grey')\n",
    "        sns.heatmap(df_background, ax=ax1,cmap=generate_cmap(['#DDDDDD','#bbbbbb']),cbar_kws={\"ticks\":[]},cbar=False)\n",
    "        sns.heatmap(df_time  , ax=ax2,cmap='Spectral_r',vmin=-1, vmax=1,cbar=False)\n",
    "        plt.savefig(\"figures/NK_0148_c_runtime_\"+title+\".pdf\", bbox_inches = 'tight')\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        ax1 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"a\")\n",
    "        ax2 = fig.add_axes([0.1,0.1,0.8,0.8],label=\"b\")\n",
    "        ax2.patch.set_alpha(0.0)\n",
    "        ax1.set_title(title,fontsize=10)\n",
    "        ax1.patch.set_facecolor('grey')\n",
    "        sns.heatmap(df_background, ax=ax1,cmap=generate_cmap(['#DDDDDD','#bbbbbb']),cbar_kws={\"ticks\":[]},cbar=False)\n",
    "        sns.heatmap(df_memory  , ax=ax2,cmap='Spectral_r',vmin=-1, vmax=1,cbar=False)\n",
    "        plt.savefig(\"figures/NK_0148_d_memory_\"+title+\".pdf\", bbox_inches = 'tight')\n",
    "        #plt.show()\n",
    "        plt.close()"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# mu - alpha: entropy distribution\n",
    "\n",
    "def count_sequence_fast(in_fname):\n",
    "    with gzip.open(in_fname, 'rt') as handle:\n",
    "        k, l=0, 0\n",
    "        for line in handle:\n",
    "            if(line[0]==\">\"): k+=1\n",
    "            elif(k==1): l+=len(line)-1\n",
    "    return k,l # k: number of sequence, n: sequence length of first sequence (outgroup)\n",
    "\n",
    "    return max_ratio\n",
    "\n",
    "def count_table(fasta):\n",
    "    seqcount,length=count_sequence_fast(fasta)\n",
    "    ACGT_to_i={'A':0,'C':1,'G':2,'T':3}\n",
    "    \n",
    "    cnt_matrix=np.array([[0]*4]*length)\n",
    "    \n",
    "    with gzip.open(fasta, 'rt') as handle:\n",
    "        sequences=SeqIO.parse(handle,'fasta')\n",
    "        i=0\n",
    "        for record in sequences:\n",
    "            for k in range(length):\n",
    "                cnt_matrix[k][ACGT_to_i[record.seq[k]]]+=1\n",
    "    return cnt_matrix\n",
    "\n",
    "def calculate_bit_score(fasta):\n",
    "    table=count_table(fasta)\n",
    "    bit_score_list=[]\n",
    "    for i in range(len(table)):\n",
    "        count_list=table[i]\n",
    "        count_sum=sum(count_list)\n",
    "        entropy=0\n",
    "        for count in count_list:\n",
    "            p=float(count)/count_sum\n",
    "            if(p>0):\n",
    "                entropy+=-p*np.log2(p)\n",
    "        bit_score=2-entropy\n",
    "        bit_score_list.append(bit_score)\n",
    "    return bit_score_list\n",
    "\n",
    "def bit_score(bins, fasta_file_list):\n",
    "    fasta_list=[]\n",
    "    for filename in fasta_file_list:\n",
    "        fasta_list.append(filename)\n",
    "    for fasta in fasta_list:\n",
    "        print(\"reading \"+fasta)\n",
    "        bit_score_list=calculate_bit_score(fasta)\n",
    "\n",
    "        # draw histogram\n",
    "        fig = plt.figure(figsize=(2,2))\n",
    "        ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "        ax.hist(bit_score_list, range=(0, 2), color=\"#4294C3\", bins=bins, alpha=1)\n",
    "\n",
    "        filename_list=fasta.split(\"/\")\n",
    "        ax.set_title(filename_list[len(filename_list)-1])\n",
    "        ax.set_xlabel(\"Bit Score\")\n",
    "        ax.set_xlim(0,2)\n",
    "        ax.set_ylim(0,1000)\n",
    "        ax.tick_params(bottom = False, left = False)\n",
    "        plt.savefig(\"figures/NK_0148_\"+fasta.split(\"/\")[-1]+\".Bit_score_histogram.pdf\",bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "file_list = []\n",
    "for task_id in [1, 11, 24, 289, 312, 577, 587, 600]:\n",
    "    file_list.append(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/mu_alpha_seq/downloaded/PRESUMEout.\"+str(task_id)+\".fa.gz\")\n",
    "bit_score(30, file_list)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sigma -mu nhd map\n",
    "df_nhd = pd.read_csv(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/sigma_mu_nhd/taskid_mu_sigma_nhd_50percentile.csv\", names = ['task_id', 'mu', 'sigma', 'nhd'])\n",
    "\n",
    "mu_list    = list(sorted(set(list(df_nhd['mu']))))\n",
    "sigma_list = list(reversed(sorted(set(list(df_nhd['sigma'])))))\n",
    "mu2colidx    = {mu: idx    for idx, mu    in enumerate(mu_list   )}\n",
    "sigma2rowidx = {sigma: idx for idx, sigma in enumerate(sigma_list)}\n",
    "mtx_nhd = np.zeros((len(sigma_list), len(mu_list))); mtx_nhd[:,:] = np.nan\n",
    "for mu, sigma, nhd in zip(df_nhd['mu'], df_nhd['sigma'], df_nhd['nhd']):\n",
    "    mtx_nhd[sigma2rowidx[sigma]][mu2colidx[mu]] = np.log10(nhd)\n",
    "    #mtx_nhd[sigma2rowidx[sigma]][mu2colidx[mu]] = nhd)\n",
    "df_nhdmtx = pd.DataFrame(mtx_nhd, index = sigma_list, columns = mu_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cmap = \"Spectral_r\"\n",
    "vmin = -2.5\n",
    "vmax = 00\n",
    "\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "ax  = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax2 = fig.add_axes([0.1 + 0.9, 0.45,0.4,0.1])\n",
    "ax.patch.set_facecolor('grey')\n",
    "sns.heatmap(df_nhdmtx, cmap=cmap, ax=ax, cbar_ax=ax2, cbar_kws={'orientation': 'horizontal'}, vmin=vmin, vmax=vmax)\n",
    "ax.set_title(\"NHD\")\n",
    "ax.set_xlabel(\"$\\mu$\")\n",
    "ax.set_ylabel(\"$\\\\sigma$\")\n",
    "ax.set_xticks([0.5,5.5,10.5,15.5,20.5])\n",
    "ax.set_xticklabels(['0.01','0.032','0.10','0.32','1.0'])\n",
    "ax.set_yticks([0.5, 10.5, 20.5, 30.5])\n",
    "ax.set_yticklabels(['3.0','2.0','1.0','0.0'])\n",
    "ax2.set_xticklabels([\"\", \"$10^{-2}$\", \"\", \"$10^{-1}$\", \"\", \"$1$\"])\n",
    "plt.savefig(\"figures/NK_0148_sigma_mu_nhd.pdf\", bbox_inches='tight')\n",
    "#plt.show()\n",
    "plt.close()\n",
    "\n",
    "for method in [\"rapidnjNJ\", \"raxmlMP\", \"fasttreeML\"]:\n",
    "\n",
    "    df_accuracy_fractal_1, df_coverage_fractal_1   = sigma_mu_read_data(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/sigma_mu/result.\"+method+\"_fractal.csv\")\n",
    "    df_accuracy_original_1, df_coverage_original_1 = sigma_mu_read_data(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/sigma_mu/result.\"+method+\"_original.csv\")\n",
    "\n",
    "    df_accuracy_fractal_2, df_coverage_fractal_2   = sigma_mu_read_data(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/sigma_mu/result.\"+method+\"_fractal.2.csv\")\n",
    "    df_accuracy_original_2, df_coverage_original_2 = sigma_mu_read_data(\"/Users/nk/Documents/backupped/Research/YachieLabLocal/FRACTAL/data/NK_0148/result/sigma_mu/result.\"+method+\"_original.2.csv\")\n",
    "\n",
    "    df_accuracy_fractal_max = np.maximum(df_accuracy_fractal_1.replace(np.nan, -1), df_accuracy_fractal_2.replace(np.nan, -1)).replace(-1, np.nan)\n",
    "    df_coverage_fractal_max = np.maximum(df_coverage_fractal_1.replace(np.nan, -1), df_coverage_fractal_2.replace(np.nan, -1)).replace(-1, np.nan)\n",
    "\n",
    "    for df_accuracy_fractal, df_coverage_fractal, df_accuracy_original, df_coverage_original, df_label in [(df_accuracy_fractal_1, df_coverage_fractal_1, df_accuracy_original_1, df_coverage_original_1, \"1\"), (df_accuracy_fractal_2, df_coverage_fractal_2, df_accuracy_original_2, df_coverage_original_2, \"2\"), (df_accuracy_fractal_max, df_coverage_fractal_max, df_accuracy_original_2, df_coverage_original_2, \"max\")]:\n",
    "\n",
    "        #print(\"point 1\")\n",
    "        df_accuracy_diff = df_accuracy_fractal - df_accuracy_original\n",
    "        #print(\"point 2\")\n",
    "        df_comparable_TF = (df_accuracy_diff >= -5) #* (df_coverage_fractal >= 99) \n",
    "        #print(\"point 3\")\n",
    "        df_comparable = df_comparable_TF.replace(False, \"\").replace(True, \"*\")\n",
    "        #print(\"point 4\")\n",
    "\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        ax  = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "        ax3 = fig.add_axes([0.1 + 0.9, 0.45,0.5,0.1], label = 'b')\n",
    "        ax2 = fig.add_axes([0.1 + 0.9, 0.45,0.5,0.1], label = 'a')\n",
    "        ax.patch.set_facecolor('grey')\n",
    "        sns.heatmap(df_nhdmtx, cmap=cmap, ax=ax, cbar_ax=ax2, annot = df_comparable, fmt = '', annot_kws={'fontsize':5}, cbar_kws={'orientation': 'horizontal'}, vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(\"NHD \"+method+\"_\"+df_label)\n",
    "        ax.set_xlabel(\"$\\mu$\")\n",
    "        ax.set_ylabel(\"$\\\\sigma$\")\n",
    "        ax.set_xticks([0.5,5.5,10.5,15.5,20.5])\n",
    "        ax.set_xticklabels(['0.01','0.032','0.10','0.32','1.0'])\n",
    "        ax.set_yticks([0.5, 10.5, 20.5, 30.5])\n",
    "        ax.set_yticklabels(['3.0','2.0','1.0','0.0'])\n",
    "        ax2.tick_params(bottom=False, labelbottom=False)\n",
    "        ax3.set_xlim(10**vmin, 10**vmax)\n",
    "        ax3.set_xscale(\"log\")\n",
    "        ax3.tick_params(left=False, labelleft=False)\n",
    "        ax3.spines[\"right\"].set_color(\"none\")\n",
    "        ax3.spines[\"left\"].set_color(\"none\")\n",
    "        ax3.spines[\"top\"].set_color(\"none\")\n",
    "        ax3.spines[\"bottom\"].set_color(\"none\")\n",
    "        \n",
    "        #ax2.set_xticklabels([\"\", \"$10^{-2}$\", \"\", \"$10^{-1}$\", \"\", \"$0$\"])\n",
    "        #ax2.set_xticklabels([\"$10^{-2}$\", \"$10^{-1}$\", \"$0$\"])\n",
    "        plt.savefig(\"figures/NK_0148_sigma_mu_\"+method+\"_\"+df_label+\"_comparable.pdf\", bbox_inches='tight')\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    mhd_comparable_list = []\n",
    "    for i, sigma in enumerate(list(df_comparable.index)):\n",
    "        for j, mu in enumerate(list(df_comparable.columns)):\n",
    "            mhd_comparable_list.append([sigma, mu, df_comparable_TF.iloc[i,j], df_nhdmtx.iloc[i,j],df_accuracy_original.iloc[i,j]])\n",
    "    df_mhd_comparable = pd.DataFrame(mhd_comparable_list, columns = [\"sigma\", 'mu', 'compararble', 'logmhd', 'Original'])\n",
    "    df_mhd_comparable['total_datacount'] = 1\n",
    "    df_mhd_comparable['logmhd_class'] = [int(logmhd*10)/10 for logmhd in df_mhd_comparable['logmhd']]\n",
    "    df_mhd_comparable_bin = df_mhd_comparable.groupby('logmhd_class').sum()\n",
    "    df_mhd_comparable_bin['Original_med'] = df_mhd_comparable.groupby('logmhd_class').median()['Original']\n",
    "    fig = plt.figure(figsize=(3,2))\n",
    "    ax  = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    ax.bar(x = df_mhd_comparable_bin.index, height = df_mhd_comparable_bin['compararble']/df_mhd_comparable_bin['total_datacount']*100, width =0.1, color = '#3F8F92', )\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(df_mhd_comparable_bin.index, df_mhd_comparable_bin['Original_med'], color = '#1432F5')\n",
    "    ax.set_ylim(0,105)\n",
    "    ax2.set_ylim(0,105)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    ax.set_xticks([-2.05,-1.05,0.05])\n",
    "    ax.set_xticklabels([\"1\",\"10\",\"100\"])\n",
    "    ax.set_xlabel(\"Median of Normalized Hamming Distance\")\n",
    "    ax.set_ylabel(\"%condition\")\n",
    "    ax2.set_ylabel(\"Median\\naccuracy (%)\")\n",
    "    ax.set_title(method+\"_\"+df_label)\n",
    "    plt.savefig(\"figures/NK_0148_sigma_mu_ratio_comparable\"+method+\"_\"+df_label+\".pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(10,2))\n",
    "    ax  = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "    sns.violinplot(x = 'logmhd_class', y = 'Original', data = df_mhd_comparable, hue = 'compararble',ax =ax)\n",
    "    ax.set_xlabel(\"Log median of Normalized Hamming Distance\")\n",
    "    ax.set_ylabel(\"Median accuracy\\nof original (%)\")\n",
    "    ax.set_title(method+\"_\"+df_label)\n",
    "    plt.savefig(\"figures/NK_0148_sigma_mu_ratio_comparable_\"+method+\"_\"+df_label+\".pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    original_accuracy_threshold = 70\n",
    "    df_mhd_comparable_bin['Ratio'] = df_mhd_comparable_bin['compararble']/df_mhd_comparable_bin['total_datacount']\n",
    "    print(\n",
    "        \"For each MNHD bin in which original software accomplished accuracy of >\",original_accuracy_threshold,\"%, fractalized software performance was comparable with original one for >\", df_mhd_comparable_bin[df_mhd_comparable_bin['Original_med'] > original_accuracy_threshold]['Ratio'].min()*100, \"% of conditions\"\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_comparable_TF.iloc[0,0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_nhdmtx.iloc[0,0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mhd_comparable_list = []\n",
    "for i, sigma in enumerate(list(df_comparable.index)):\n",
    "    for j, mu in enumerate(list(df_comparable.columns)):\n",
    "        mhd_comparable_list.append([sigma, mu, df_comparable_TF.iloc[i,j], df_nhdmtx.iloc[i,j],df_accuracy_original.iloc[i,j]])\n",
    "df_mhd_comparable = pd.DataFrame(mhd_comparable_list, columns = [\"sigma\", 'mu', 'compararble', 'logmhd', 'Original'])\n",
    "df_mhd_comparable['total_datacount'] = 1\n",
    "df_mhd_comparable['logmhd_class'] = [int(logmhd*10)/10 for logmhd in df_mhd_comparable['logmhd']]\n",
    "df_mhd_comparable_bin = df_mhd_comparable.groupby('logmhd_class').sum()\n",
    "df_mhd_comparable_bin['Original_med'] = df_mhd_comparable.groupby('logmhd_class').median()['Original']\n",
    "df_mhd_comparable_bin['Ratio'] = df_mhd_comparable_bin['compararble']/df_mhd_comparable_bin['total_datacount']\n",
    "df_mhd_comparable_bin[df_mhd_comparable_bin['Original_med'] > 70]['Ratio'].min()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(3,2))\n",
    "ax  = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax.bar(x = df_mhd_comparable_bin.index, height = df_mhd_comparable_bin['compararble']/df_mhd_comparable_bin['total_datacount']*100, width =0.1, color = '#3F8F92', )\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(df_mhd_comparable_bin.index, df_mhd_comparable_bin['Original_med'], color = '#1432F5')\n",
    "\n",
    "ax.set_ylim(0,105)\n",
    "ax2.set_ylim(0,105)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "ax.set_xticks([-2.05,-1.05,0.05])\n",
    "ax.set_xticklabels([\"1\",\"10\",\"100\"])\n",
    "ax.set_xlabel(\"Median of Normalized Hamming Distance (%)\")\n",
    "ax.set_ylabel(\"%condition\")\n",
    "ax2.set_ylabel(\"Median\\naccuracy (%)\")\n",
    "\n",
    "plt.savefig(\"figures/NK_0148_sigma_mu_ratio_comparable.pdf\", bbox_inches='tight')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}